import os
import json

from tqdm import tqdm
from utils.llm import client
from concurrent.futures import ThreadPoolExecutor, as_completed
from src.corpus_generation.cot_synthesis.prompt import TUNE_TEMPLATE


def build_prompt(json_data) -> str:
    cur_config = json.dumps(json_data["config"], ensure_ascii=False, indent=2)
    bottleneck_report = "\n".join(f"- {b}" for b in json_data.get("bottlenecks", []))

    system = json_data["system"]
    workload = json_data.get("workload", {})
    app_name = json_data["app_name"]

    system_info_parts = [
        f"æ“ä½œç³»ç»Ÿç‰ˆæœ¬ï¼š{system.get('os_version')}",
        f"CPU ä¿¡æ¯ï¼š{system.get('cpu_info')}",
        f"å†…å­˜é…ç½®ï¼š{system.get('memory_info')}",
        f"å­˜å‚¨ç±»å‹ï¼š{system.get('storage_type')}",
        f"ç½‘ç»œç¯å¢ƒï¼š{system.get('network_info')}",
        f"è¿è¡Œç¯å¢ƒï¼š{system.get('runtime_environment')}",
    ]

    if "system" in workload:
        system_info_parts.append("ç³»ç»Ÿè¿è¡ŒæŒ‡æ ‡ï¼š")
        for k, v in workload["system"].items():
            system_info_parts.append(f"- {k}: {v}")

    if app_name in workload:
        system_info_parts.append(f"{app_name} è¿è¡ŒæŒ‡æ ‡ï¼š")
        for k, v in workload[app_name].items():
            system_info_parts.append(f"- {k}: {v}")

    system_info_str = "\n".join(system_info_parts)
    param_knowledge = json_data.get("param_knowledge", "")

    return (
        TUNE_TEMPLATE.replace("{$CUR_CONFIG}", cur_config)
        .replace("{$BOTTLENECK_REPORT}", bottleneck_report)
        .replace("{$SYSTEM_INFO}", system_info_str)
        .replace("{$PARAM_KNOWLEDGE}", param_knowledge)
    )


def run_synthesis(
    app_name: str,
    out_file: str = "data/synthesis/train_data.jsonl",
    max_workers: int = 8,
):
    workload_dir = f"data/synthesis_data/workload/{app_name}"
    if not os.path.exists(workload_dir):
        print(f"[âŒ] ç›®å½•ä¸å­˜åœ¨: {workload_dir}")
        return

    files = sorted(f for f in os.listdir(workload_dir) if f.endswith(".json"))
    if not files:
        print(f"[âš ï¸] æ— æ•°æ®æ–‡ä»¶: {workload_dir}")
        return

    os.makedirs(os.path.dirname(out_file), exist_ok=True)
    print(f"[ğŸš€] å¼€å§‹å¹¶å‘å¤„ç† {len(files)} æ¡ workload æ•°æ®")

    def process_file(fname: str):
        try:
            file_path = os.path.join(workload_dir, fname)
            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)

            prompt = build_prompt(data)
            answer = client.call_chatgpt(prompt)

            if not answer:
                raise ValueError("æ¨¡å‹è¿”å›ä¸ºç©º")

            item =  {
                "instruction": prompt.strip(),
                "input": "",
                "output": answer.strip(),
            }
            with open(out_file, "a", encoding="utf-8") as out_fp:
                out_fp.write(json.dumps(item, ensure_ascii=False) + "\n")
        except Exception as e:
            print(f"[âŒ] å¤„ç†å¤±è´¥ ({fname}): {e}")
            return None

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(process_file, fname): fname for fname in files}

        for future in tqdm(
            as_completed(futures), total=len(futures), desc="å¹¶å‘åˆæˆæ•°æ®"
        ):
            future.result()


# ç¤ºä¾‹è°ƒç”¨
if __name__ == "__main__":
    run_synthesis("mysql")  # ä¿®æ”¹ä¸ºä½ è¦å¤„ç†çš„ app_name
